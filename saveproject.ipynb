{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1jNa7IMxVaMk1datQtDzBHrEVeLTOD0Uc",
      "authorship_tag": "ABX9TyMf1Urpz/j6uzqOvpu1f42B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/643020514-7/643020514-7/blob/main/saveproject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Prototype"
      ],
      "metadata": {
        "id": "Bp5CDRhqLMhZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "# Assuming 'hote2' DataFrame has a 'Review' column\n",
        "reviews = hote2['Review']\n",
        "\n",
        "# Define a function to remove words with a length less than 2\n",
        "def remove_less_than_2(text):\n",
        "    return ' '.join([word for word in text.split() if len(word) > 2])\n",
        "\n",
        "# Apply the function to the 'Review' column and create a new 'Processed_Review' column\n",
        "hote2['Processed_Review'] = reviews.apply(remove_less_than_2)\n",
        "\n",
        "# Filter reviews based on ratings\n",
        "positive_reviews = []\n",
        "negative_reviews = []  # Modified to store all negative reviews\n",
        "\n",
        "# Create a SentimentIntensityAnalyzer instance\n",
        "sid = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Perform sentiment analysis on each review\n",
        "for index, row in hote2.iterrows():\n",
        "    sentiment_scores = sid.polarity_scores(row['Processed_Review'])\n",
        "    compound_score = sentiment_scores['compound']\n",
        "\n",
        "    if \"not bad\" in row['Processed_Review']:\n",
        "        negative_reviews.append(row['Review'])  # If \"not bad\" is present, add it to negative reviews\n",
        "    elif compound_score >= 0.1:\n",
        "        positive_reviews.append(row['Review'])\n",
        "    elif compound_score <= -0.1:\n",
        "        negative_reviews.append(row['Review'])  # All other negative reviews\n",
        "\n",
        "# Display the filtered reviews based on sentiment analysis\n",
        "print(\"\\nPositive Reviews:\")\n",
        "for review in positive_reviews:\n",
        "    print(review)\n",
        "\n",
        "print(\"\\nNeutral Reviews:\")  # No change in neutral reviews\n",
        "\n",
        "print(\"\\nNegative Reviews:\")\n",
        "for review in negative_reviews:\n",
        "    print(review)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aT8uZpLmLQpj",
        "outputId": "403fb733-52df-4bdf-d984-83e6670e8a7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Positive Reviews:\n",
            "good nice ,well done i like it\n",
            "i'm fine it's ok better\n",
            "good nice i like it's so much ,l love it\n",
            "good nice ,well done i like it\n",
            "i'm fine it's ok better\n",
            "good nice i like it's so much ,l love it\n",
            "\n",
            "Neutral Reviews:\n",
            "\n",
            "Negative Reviews:\n",
            "i think that's not good\n",
            "so bad #@fk ,have problem\n",
            "i think that's not good\n",
            "so bad #@fk ,have problem\n",
            "good nice i like it's so much ,l love it and not bad\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "code in project save"
      ],
      "metadata": {
        "id": "LZ8gP1BkLL1i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#สร้าง reviews,ratings จาก hotel\n",
        "reviews = hotel['Review']\n",
        "ratings = hotel['Rating']\n",
        "\n",
        "# สร้าง DataFrame\n",
        "df = pd.DataFrame({'Review': reviews, 'Rating': ratings})\n",
        "\n",
        "# (กำกับการให้คะแนนโดยมี positive,negative,neutral)\n",
        "def label_sentiment(rating):\n",
        "    if rating >= 4:\n",
        "        return 'Positive'\n",
        "    elif rating <= 2:\n",
        "        return 'Negative'\n",
        "    else:\n",
        "        return 'Neutral'\n",
        "\n",
        "df['Sentiment'] = df['Rating'].apply(label_sentiment)\n",
        "\n",
        "\n",
        "# ทำการรวมข้อความของแค่ละreviews คือ positive,negative,neutral โดยใช้ , เป็นตัวคั่นระหว่างข้อความแต่ละรีวิว.\n",
        "positive_reviews_a = \" \".join(df[df['Sentiment'] == 'Positive']['Review'])\n",
        "negative_reviews_a = \" \".join(df[df['Sentiment'] == 'Negative']['Review'])\n",
        "neutral_reviews_a = \" \".join(df[df['Sentiment'] == 'Neutral']['Review'])\n",
        "\n",
        "# นำข้อความในแต่ละกลุ่มที่รวมไว้แล้วแยกออกมาเป็นรีวิวแต่ละรีวิวด้วยการใช้ , เป็นตัวคั่นและสร้าง DataFrame\n",
        "aa = positive_reviews_a.split(',')\n",
        "bb = negative_reviews_a.split(',')\n",
        "cc = neutral_reviews_a.split(',')\n",
        "# DataFrame แยกตามกลุ่ม\n",
        "df_pos = pd.DataFrame({'Review': aa})\n",
        "df_neg = pd.DataFrame({'Review': bb})\n",
        "df_neu = pd.DataFrame({'Review': cc})\n",
        "\n",
        "\n",
        "positive_reviews = []\n",
        "negative_reviews = []\n",
        "neutral_reviews = []\n",
        "\n",
        "sid = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Zip the three DataFrames together\n",
        "for review1, review2, review3 in zip(df_pos['Review'], df_neg['Review'],df_neu['Review']):\n",
        "    # Perform sentiment analysis on each review\n",
        "    sentiment_scores1 = sid.polarity_scores(review1)\n",
        "    sentiment_scores2 = sid.polarity_scores(review2)\n",
        "    sentiment_scores3 = sid.polarity_scores(review3)\n",
        "\n",
        "    compound_score1 = sentiment_scores1['compound']\n",
        "    compound_score2 = sentiment_scores2['compound']\n",
        "    compound_score3 = sentiment_scores3['compound']\n",
        "\n",
        "    # Combine positive reviews from all three DataFrames\n",
        "    if compound_score1 >= 0.1:\n",
        "        positive_reviews.append(review1)\n",
        "    if compound_score2 >= 0.1:\n",
        "        positive_reviews.append(review2)\n",
        "    if compound_score3 >= 0.1:\n",
        "        positive_reviews.append(review3)\n",
        "\n",
        "    # Combine negative reviews from all three DataFrames\n",
        "    if compound_score1 <= -0.1:\n",
        "        negative_reviews.append(review1)\n",
        "    if compound_score2 <= -0.1:\n",
        "        negative_reviews.append(review2)\n",
        "    if compound_score3 <= -0.1:\n",
        "        negative_reviews.append(review3)\n",
        "\n",
        "    # Combine neutral reviews from all three DataFrames\n",
        "    if -0.1 < compound_score1 < 0.1:\n",
        "        neutral_reviews.append(review1)\n",
        "    if -0.1 < compound_score2 < 0.1:\n",
        "        neutral_reviews.append(review2)\n",
        "    if -0.1 < compound_score3 < 0.1:\n",
        "        neutral_reviews.append(review3)\n",
        "\n",
        "#การทำความสะอาดและlemmatizeข้อความ\n",
        "# Create a WordNet Lemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "#  lemmatize text\n",
        "def preprocess_and_lemmatize(text):\n",
        "    # Tokenization\n",
        "    words = nltk.word_tokenize(text)\n",
        "\n",
        "    # Lemmatization\n",
        "    words = [lemmatizer.lemmatize(word.lower()) for word in words]\n",
        "\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "\n",
        "    # ลบอักขระที่ไม่ใช่ตัวอักษร\n",
        "    words = [re.sub(r'[^a-zA-Z]', '', word) for word in words if word.isalpha()]\n",
        "\n",
        "\n",
        "    return \" \".join(words)\n",
        "\n",
        "# Apply preprocessing and lemmatization to reviews\n",
        "positive_reviews = [preprocess_and_lemmatize(review) for review in positive_reviews]\n",
        "negative_reviews = [preprocess_and_lemmatize(review) for review in negative_reviews]\n",
        "neutral_reviews = [preprocess_and_lemmatize(review) for review in neutral_reviews]\n",
        "\n",
        "\n",
        "\n",
        "# การหาความถี่ของคำ\n",
        "def word_frequency(text):\n",
        "    words = nltk.word_tokenize(text)\n",
        "    freq_dist = nltk.FreqDist(words)\n",
        "    return freq_dist\n",
        "\n",
        "positive_freq_dist = word_frequency(\" \".join(positive_reviews))\n",
        "negative_freq_dist = word_frequency(\" \".join(negative_reviews))\n",
        "neutral_freq_dist = word_frequency(\" \".join(neutral_reviews))\n",
        "\n",
        "\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# generate a word cloud\n",
        "def generate_word_cloud(text, title):\n",
        "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.imshow(wordcloud, interpolation='bilinear')\n",
        "    plt.title(title)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Generate word clouds for positive, negative, and neutral reviews\n",
        "generate_word_cloud(\" \".join(positive_reviews), 'Positive Sentiment Word Cloud')\n",
        "generate_word_cloud(\" \".join(negative_reviews), 'Negative Sentiment Word Cloud')\n",
        "generate_word_cloud(\" \".join(neutral_reviews), 'Neutral Sentiment Word Cloud')"
      ],
      "metadata": {
        "id": "ujUSFCqXLSg-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}